{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vTTS - Universal TTS/STT Serving System ì™„ì „ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**vLLM for Speech** - ëª¨ë“  TTS/STT ëª¨ë¸ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ”:\n",
    "- âœ… **Supertonic-2 TTS**: 8ê°œ ìŒì„± ìŠ¤íƒ€ì¼ Ã— 5ê°œ ì–¸ì–´\n",
    "- âœ… **Faster-Whisper STT**: 5ê°œ ëª¨ë¸ í¬ê¸° Ã— 5ê°œ ì¶œë ¥ í¬ë§·\n",
    "- ğŸ”œ **CosyVoice3 TTS**: SFT + Zero-shot ëª¨ë“œ (ì„ íƒì )\n",
    "- ğŸ”œ **GPT-SoVITS TTS**: Voice cloning (ì„ íƒì )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Part 1: ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vTTS ì„¤ì¹˜ (ëª¨ë“  ì—”ì§„ í¬í•¨)\n",
    "!pip install -q \"vtts[all] @ git+https://github.com/bellkjtt/vTTS.git\"\n",
    "\n",
    "print(\"âœ… vTTS ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    print(\"GPU ì—†ìŒ, CPU ëª¨ë“œë¡œ ì‹¤í–‰\")\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ™ï¸ Part 2: Supertonic-2 TTS ì „ì²´ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°:\n",
    "- **ìŒì„± ìŠ¤íƒ€ì¼**: M1, M2, M3, M4, F1, F2, F3, F4 (8ê°œ)\n",
    "- **ì–¸ì–´**: en, ko, es, pt, fr (5ê°œ)\n",
    "- **ì´ ì¡°í•©**: 40ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supertonic-2 ì—”ì§„ ë¡œë“œ\n",
    "from vtts.engines.supertonic import SupertonicEngine\n",
    "from vtts.engines.base import TTSRequest\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”§ Loading Supertonic-2 engine...\")\n",
    "tts_engine = SupertonicEngine()\n",
    "tts_engine.load_model()\n",
    "\n",
    "print(\"âœ… Supertonic-2 ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ì§€ì› ì–¸ì–´: {tts_engine.supported_languages}\")\n",
    "print(f\"ì§€ì› ìŒì„±: {tts_engine.supported_voices}\")\n",
    "print(f\"ìƒ˜í”Œë ˆì´íŠ¸: {tts_engine.default_sample_rate}Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "test_texts = {\n",
    "    \"ko\": \"ì•ˆë…•í•˜ì„¸ìš”, vTTS í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "    \"en\": \"Hello, this is vTTS testing.\",\n",
    "    \"es\": \"Hola, esta es una prueba de vTTS.\",\n",
    "    \"pt\": \"OlÃ¡, este Ã© um teste vTTS.\",\n",
    "    \"fr\": \"Bonjour, ceci est un test vTTS.\"\n",
    "}\n",
    "\n",
    "# ëª¨ë“  ìŒì„± ìŠ¤íƒ€ì¼\n",
    "all_voices = [\"M1\", \"M2\", \"M3\", \"M4\", \"F1\", \"F2\", \"F3\", \"F4\"]\n",
    "\n",
    "print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ ê³„íš: {len(all_voices)} voices Ã— {len(test_texts)} languages = {len(all_voices) * len(test_texts)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ìŒì„± ìŠ¤íƒ€ì¼ë³„ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ë¡œ ëª¨ë“  ìŒì„± ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ™ï¸ í•œêµ­ì–´ ìŒì„± ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸\\n\" + \"=\"*60)\n",
    "\n",
    "os.makedirs(\"outputs/supertonic/korean\", exist_ok=True)\n",
    "\n",
    "for voice in all_voices:\n",
    "    print(f\"\\nğŸ”Š Voice: {voice}\")\n",
    "    \n",
    "    request = TTSRequest(\n",
    "        text=test_texts[\"ko\"],\n",
    "        language=\"ko\",\n",
    "        voice=voice\n",
    "    )\n",
    "    \n",
    "    output = tts_engine.synthesize(request)\n",
    "    \n",
    "    # ì €ì¥\n",
    "    filename = f\"outputs/supertonic/korean/{voice}.wav\"\n",
    "    sf.write(filename, output.audio, output.sample_rate)\n",
    "    \n",
    "    # ì¬ìƒ\n",
    "    print(f\"   Duration: {len(output.audio)/output.sample_rate:.2f}s\")\n",
    "    print(f\"   File: {filename}\")\n",
    "    display(ipd.Audio(output.audio, rate=output.sample_rate))\n",
    "\n",
    "print(\"\\nâœ… í•œêµ­ì–´ ìŒì„± ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ (F1 ìŒì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 ìŒì„±ìœ¼ë¡œ ëª¨ë“  ì–¸ì–´ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸŒ ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸ (F1 voice)\\n\" + \"=\"*60)\n",
    "\n",
    "for lang, text in test_texts.items():\n",
    "    print(f\"\\nğŸ”Š Language: {lang}\")\n",
    "    print(f\"   Text: {text}\")\n",
    "    \n",
    "    request = TTSRequest(\n",
    "        text=text,\n",
    "        language=lang,\n",
    "        voice=\"F1\"\n",
    "    )\n",
    "    \n",
    "    output = tts_engine.synthesize(request)\n",
    "    \n",
    "    # ì €ì¥\n",
    "    os.makedirs(f\"outputs/supertonic/{lang}\", exist_ok=True)\n",
    "    filename = f\"outputs/supertonic/{lang}/F1.wav\"\n",
    "    sf.write(filename, output.audio, output.sample_rate)\n",
    "    \n",
    "    # ì¬ìƒ\n",
    "    print(f\"   Duration: {len(output.audio)/output.sample_rate:.2f}s\")\n",
    "    display(ipd.Audio(output.audio, rate=output.sample_rate))\n",
    "\n",
    "print(\"\\nâœ… ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ì „ì²´ ì¡°í•© í…ŒìŠ¤íŠ¸ (40ê°œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì¡°í•© í…ŒìŠ¤íŠ¸ (ìŒì„± ì¬ìƒ ì—†ì´ ì €ì¥ë§Œ)\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"ğŸš€ ì „ì²´ ì¡°í•© í…ŒìŠ¤íŠ¸ ì‹œì‘...\\n\")\n",
    "\n",
    "results = []\n",
    "total_tests = len(all_voices) * len(test_texts)\n",
    "\n",
    "with tqdm(total=total_tests, desc=\"Processing\") as pbar:\n",
    "    for voice in all_voices:\n",
    "        for lang, text in test_texts.items():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            request = TTSRequest(\n",
    "                text=text,\n",
    "                language=lang,\n",
    "                voice=voice\n",
    "            )\n",
    "            \n",
    "            output = tts_engine.synthesize(request)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # ì €ì¥\n",
    "            os.makedirs(f\"outputs/supertonic/{lang}\", exist_ok=True)\n",
    "            filename = f\"outputs/supertonic/{lang}/{voice}.wav\"\n",
    "            sf.write(filename, output.audio, output.sample_rate)\n",
    "            \n",
    "            # ê²°ê³¼ ê¸°ë¡\n",
    "            results.append({\n",
    "                \"voice\": voice,\n",
    "                \"language\": lang,\n",
    "                \"duration\": len(output.audio) / output.sample_rate,\n",
    "                \"processing_time\": elapsed,\n",
    "                \"rtf\": elapsed / (len(output.audio) / output.sample_rate),\n",
    "                \"file\": filename\n",
    "            })\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"\\nâœ… {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# í†µê³„ ì¶œë ¥\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š í†µê³„:\")\n",
    "print(f\"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {df['processing_time'].mean():.3f}s\")\n",
    "print(f\"í‰ê·  RTF: {df['rtf'].mean():.3f}x\")\n",
    "print(f\"í‰ê·  ì˜¤ë””ì˜¤ ê¸¸ì´: {df['duration'].mean():.2f}s\")\n",
    "\n",
    "# ì–¸ì–´ë³„ í†µê³„\n",
    "print(\"\\nğŸ“ˆ ì–¸ì–´ë³„ í‰ê·  RTF:\")\n",
    "print(df.groupby('language')['rtf'].mean().sort_values())\n",
    "\n",
    "# ìŒì„±ë³„ í†µê³„\n",
    "print(\"\\nğŸ¤ ìŒì„±ë³„ í‰ê·  RTF:\")\n",
    "print(df.groupby('voice')['rtf'].mean().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤ Part 3: Faster-Whisper STT ì „ì²´ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°:\n",
    "- **ëª¨ë¸ í¬ê¸°**: tiny, base, small, medium, large-v3 (5ê°œ)\n",
    "- **ì¶œë ¥ í¬ë§·**: json, verbose_json, text, srt, vtt (5ê°œ)\n",
    "- **íƒœìŠ¤í¬**: transcribe, translate\n",
    "- **ì–¸ì–´**: auto-detect, ko, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© ì˜¤ë””ì˜¤ ìƒì„± (Supertonic-2 ì‚¬ìš©)\n",
    "test_audios = {}\n",
    "\n",
    "for lang, text in test_texts.items():\n",
    "    request = TTSRequest(text=text, language=lang, voice=\"F1\")\n",
    "    output = tts_engine.synthesize(request)\n",
    "    \n",
    "    filename = f\"test_audio_{lang}.wav\"\n",
    "    sf.write(filename, output.audio, output.sample_rate)\n",
    "    test_audios[lang] = filename\n",
    "\n",
    "print(\"âœ… í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ:\")\n",
    "for lang, file in test_audios.items():\n",
    "    print(f\"   {lang}: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ëª¨ë¸ í¬ê¸°ë³„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtts.engines.faster_whisper import FasterWhisperEngine\n",
    "from vtts.engines.stt_base import STTRequest\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ í¬ê¸° (Kaggle ë©”ëª¨ë¦¬ ê³ ë ¤)\n",
    "model_sizes = [\"tiny\", \"base\", \"small\"]  # medium, large-v3ì€ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥\n",
    "\n",
    "print(\"ğŸ“ ëª¨ë¸ í¬ê¸°ë³„ í…ŒìŠ¤íŠ¸\\n\" + \"=\"*60)\n",
    "\n",
    "stt_results = []\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    print(f\"\\nğŸ”§ Loading {model_size} model...\")\n",
    "    \n",
    "    stt_engine = FasterWhisperEngine(\n",
    "        model_id=model_size,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    stt_engine.load_model()\n",
    "    \n",
    "    print(f\"âœ… {model_size} ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "    # í•œêµ­ì–´ í…ŒìŠ¤íŠ¸\n",
    "    start_time = time.time()\n",
    "    \n",
    "    request = STTRequest(\n",
    "        audio=test_audios[\"ko\"],\n",
    "        language=\"ko\",\n",
    "        response_format=\"json\"\n",
    "    )\n",
    "    \n",
    "    result = stt_engine.transcribe(request)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"   ì›ë³¸: {test_texts['ko']}\")\n",
    "    print(f\"   ì¸ì‹: {result.text}\")\n",
    "    print(f\"   ì²˜ë¦¬ ì‹œê°„: {elapsed:.3f}s\")\n",
    "    print(f\"   RTF: {elapsed/result.metadata['duration']:.3f}x\")\n",
    "    \n",
    "    stt_results.append({\n",
    "        \"model\": model_size,\n",
    "        \"language\": \"ko\",\n",
    "        \"original\": test_texts[\"ko\"],\n",
    "        \"transcribed\": result.text,\n",
    "        \"processing_time\": elapsed,\n",
    "        \"rtf\": elapsed / result.metadata['duration']\n",
    "    })\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    stt_engine.unload_model()\n",
    "    del stt_engine\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ í¬ê¸°ë³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ì¶œë ¥ í¬ë§·ë³„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ ì¶œë ¥ í¬ë§· í…ŒìŠ¤íŠ¸\n",
    "stt_engine = FasterWhisperEngine(model_id=\"base\", device=DEVICE)\n",
    "stt_engine.load_model()\n",
    "\n",
    "output_formats = [\"json\", \"verbose_json\", \"text\", \"srt\", \"vtt\"]\n",
    "\n",
    "print(\"ğŸ“„ ì¶œë ¥ í¬ë§·ë³„ í…ŒìŠ¤íŠ¸\\n\" + \"=\"*60)\n",
    "\n",
    "for fmt in output_formats:\n",
    "    print(f\"\\nğŸ“‹ Format: {fmt}\")\n",
    "    \n",
    "    request = STTRequest(\n",
    "        audio=test_audios[\"ko\"],\n",
    "        language=\"ko\",\n",
    "        response_format=fmt\n",
    "    )\n",
    "    \n",
    "    result = stt_engine.transcribe(request)\n",
    "    \n",
    "    print(f\"   Text: {result.text[:100]}...\" if len(result.text) > 100 else f\"   Text: {result.text}\")\n",
    "    \n",
    "    # SRT/VTTëŠ” ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ í‘œì‹œ\n",
    "    if fmt in [\"srt\", \"vtt\", \"verbose_json\"] and result.segments:\n",
    "        print(f\"   Segments: {len(result.segments)}ê°œ\")\n",
    "        if result.segments:\n",
    "            seg = result.segments[0]\n",
    "            print(f\"   ì²« ì„¸ê·¸ë¨¼íŠ¸: [{seg['start']:.2f}s-{seg['end']:.2f}s] {seg['text']}\")\n",
    "\n",
    "print(\"\\nâœ… ì¶œë ¥ í¬ë§· í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ë²ˆì—­ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ â†’ ì˜ì–´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸŒ ë²ˆì—­ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ â†’ ì˜ì–´)\\n\" + \"=\"*60)\n",
    "\n",
    "request_translate = STTRequest(\n",
    "    audio=test_audios[\"ko\"],\n",
    "    task=\"translate\",  # ë²ˆì—­ ëª¨ë“œ\n",
    "    response_format=\"json\"\n",
    ")\n",
    "\n",
    "result_translate = stt_engine.transcribe(request_translate)\n",
    "\n",
    "print(f\"ì›ë³¸ (í•œêµ­ì–´): {test_texts['ko']}\")\n",
    "print(f\"ë²ˆì—­ (ì˜ì–´): {result_translate.text}\")\n",
    "print(\"\\nâœ… ë²ˆì—­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ë‹¤êµ­ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸŒ ë‹¤êµ­ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸\\n\" + \"=\"*60)\n",
    "\n",
    "for lang, audio_file in test_audios.items():\n",
    "    print(f\"\\nğŸ”Š Language: {lang}\")\n",
    "    \n",
    "    # ì–¸ì–´ ìë™ ê°ì§€\n",
    "    request = STTRequest(\n",
    "        audio=audio_file,\n",
    "        response_format=\"json\"\n",
    "    )\n",
    "    \n",
    "    result = stt_engine.transcribe(request)\n",
    "    \n",
    "    print(f\"   ì›ë³¸: {test_texts[lang]}\")\n",
    "    print(f\"   ì¸ì‹: {result.text}\")\n",
    "    print(f\"   ê°ì§€ëœ ì–¸ì–´: {result.language}\")\n",
    "    print(f\"   ì‹ ë¢°ë„: {result.metadata['language_probability']:.2%}\")\n",
    "\n",
    "print(\"\\nâœ… ë‹¤êµ­ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 4: TTS + STT í†µí•© í…ŒìŠ¤íŠ¸ (Round-trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Round-trip í…ŒìŠ¤íŠ¸ (TTS â†’ STT)\\n\" + \"=\"*60)\n",
    "\n",
    "roundtrip_results = []\n",
    "\n",
    "for lang, original_text in test_texts.items():\n",
    "    print(f\"\\nğŸ”Š Language: {lang}\")\n",
    "    \n",
    "    # TTS: ìŒì„± ìƒì„±\n",
    "    tts_request = TTSRequest(\n",
    "        text=original_text,\n",
    "        language=lang,\n",
    "        voice=\"F1\"\n",
    "    )\n",
    "    tts_output = tts_engine.synthesize(tts_request)\n",
    "    \n",
    "    # ì„ì‹œ íŒŒì¼ ì €ì¥\n",
    "    temp_audio = f\"temp_{lang}.wav\"\n",
    "    sf.write(temp_audio, tts_output.audio, tts_output.sample_rate)\n",
    "    \n",
    "    # STT: ìŒì„± ì¸ì‹\n",
    "    stt_request = STTRequest(\n",
    "        audio=temp_audio,\n",
    "        language=lang,\n",
    "        response_format=\"json\"\n",
    "    )\n",
    "    stt_output = stt_engine.transcribe(stt_request)\n",
    "    \n",
    "    print(f\"   ì›ë³¸ í…ìŠ¤íŠ¸: {original_text}\")\n",
    "    print(f\"   ì¸ì‹ëœ í…ìŠ¤íŠ¸: {stt_output.text}\")\n",
    "    \n",
    "    # ì •í™•ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë¬¸ì ì¼ì¹˜ìœ¨)\n",
    "    original_clean = original_text.lower().replace(\" \", \"\").replace(\",\", \"\").replace(\".\", \"\")\n",
    "    transcribed_clean = stt_output.text.lower().replace(\" \", \"\").replace(\",\", \"\").replace(\".\", \"\")\n",
    "    \n",
    "    # Levenshtein ê±°ë¦¬ ëŒ€ì‹  ê°„ë‹¨í•œ ë§¤ì¹­\n",
    "    matches = sum(1 for a, b in zip(original_clean, transcribed_clean) if a == b)\n",
    "    accuracy = matches / max(len(original_clean), len(transcribed_clean)) * 100\n",
    "    \n",
    "    print(f\"   ë¬¸ì ì¼ì¹˜ìœ¨: {accuracy:.1f}%\")\n",
    "    \n",
    "    roundtrip_results.append({\n",
    "        \"language\": lang,\n",
    "        \"original\": original_text,\n",
    "        \"transcribed\": stt_output.text,\n",
    "        \"accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "print(\"\\nâœ… Round-trip í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# í†µê³„\n",
    "df_roundtrip = pd.DataFrame(roundtrip_results)\n",
    "print(f\"\\nğŸ“Š í‰ê·  ì •í™•ë„: {df_roundtrip['accuracy'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 5: ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "final_results = {\n",
    "    \"environment\": {\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"device\": DEVICE,\n",
    "        \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "    },\n",
    "    \"tts_tests\": {\n",
    "        \"engine\": \"Supertonic-2\",\n",
    "        \"total_tests\": len(results),\n",
    "        \"voices_tested\": all_voices,\n",
    "        \"languages_tested\": list(test_texts.keys()),\n",
    "        \"avg_rtf\": df['rtf'].mean(),\n",
    "        \"results\": results\n",
    "    },\n",
    "    \"stt_tests\": {\n",
    "        \"engine\": \"Faster-Whisper\",\n",
    "        \"models_tested\": model_sizes,\n",
    "        \"formats_tested\": output_formats,\n",
    "        \"results\": stt_results\n",
    "    },\n",
    "    \"roundtrip_tests\": {\n",
    "        \"avg_accuracy\": df_roundtrip['accuracy'].mean(),\n",
    "        \"results\": roundtrip_results\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON ì €ì¥\n",
    "with open('vtts_complete_test_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: vtts_complete_test_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ìš”ì•½ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ vTTS ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"âœ… ì™„ë£Œëœ í…ŒìŠ¤íŠ¸:\")\n",
    "print(f\"  ğŸ“¦ í™˜ê²½: {DEVICE.upper()}\")\n",
    "print()\n",
    "print(\"  ğŸ™ï¸ TTS (Supertonic-2):\")\n",
    "print(f\"     - ìŒì„± ìŠ¤íƒ€ì¼: {len(all_voices)}ê°œ\")\n",
    "print(f\"     - ì–¸ì–´: {len(test_texts)}ê°œ\")\n",
    "print(f\"     - ì´ í…ŒìŠ¤íŠ¸: {len(results)}ê°œ\")\n",
    "print(f\"     - í‰ê·  RTF: {df['rtf'].mean():.3f}x\")\n",
    "print()\n",
    "print(\"  ğŸ¤ STT (Faster-Whisper):\")\n",
    "print(f\"     - ëª¨ë¸ í¬ê¸°: {len(model_sizes)}ê°œ\")\n",
    "print(f\"     - ì¶œë ¥ í¬ë§·: {len(output_formats)}ê°œ\")\n",
    "print(f\"     - ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸: {len(test_texts)}ê°œ\")\n",
    "print()\n",
    "print(\"  ğŸ”„ Round-trip:\")\n",
    "print(f\"     - í‰ê·  ì •í™•ë„: {df_roundtrip['accuracy'].mean():.1f}%\")\n",
    "print()\n",
    "print(\"ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "print(f\"  - TTS í‰ê·  ì²˜ë¦¬ ì‹œê°„: {df['processing_time'].mean():.3f}s\")\n",
    "print(f\"  - TTS í‰ê·  RTF: {df['rtf'].mean():.3f}x\")\n",
    "print(f\"  - STT í‰ê·  RTF: {pd.DataFrame(stt_results)['rtf'].mean():.3f}x\")\n",
    "print()\n",
    "print(\"ğŸš€ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"  - GitHub: https://github.com/bellkjtt/vTTS\")\n",
    "print(\"  - pip install 'vtts[all] @ git+https://github.com/bellkjtt/vTTS.git'\")\n",
    "print(\"  - vtts serve Supertone/supertonic-2 --stt-model large-v3\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”œ Part 6: CosyVoice3 TTS í…ŒìŠ¤íŠ¸ (ì„ íƒì )\n",
    "\n",
    "âš ï¸ **ì£¼ì˜**: CosyVoice3ëŠ” Git cloneì´ í•„ìš”í•©ë‹ˆë‹¤. Kaggleì—ì„œëŠ” ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosyVoice3 í…ŒìŠ¤íŠ¸ (ì„ íƒì )\n",
    "# ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ ì œê±°\n",
    "\n",
    "# # CosyVoice í´ë¡ \n",
    "# !git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git\n",
    "# \n",
    "# # PYTHONPATH ì„¤ì •\n",
    "# import sys\n",
    "# sys.path.insert(0, './CosyVoice')\n",
    "# \n",
    "# # CosyVoice ì—”ì§„ ë¡œë“œ\n",
    "# from vtts.engines.cosyvoice import CosyVoiceEngine\n",
    "# \n",
    "# cosyvoice = CosyVoiceEngine(model_id=\"FunAudioLLM/Fun-CosyVoice3-0.5B-2512\")\n",
    "# cosyvoice.load_model()\n",
    "# \n",
    "# # SFT ëª¨ë“œ í…ŒìŠ¤íŠ¸\n",
    "# request = TTSRequest(\n",
    "#     text=\"ì•ˆë…•í•˜ì„¸ìš”, CosyVoice3 í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "#     language=\"ko\",\n",
    "#     voice=\"chinese_female\"\n",
    "# )\n",
    "# output = cosyvoice.synthesize(request)\n",
    "# \n",
    "# # Zero-shot ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ì°¸ì¡° ì˜¤ë””ì˜¤ í•„ìš”)\n",
    "# # request_zs = TTSRequest(\n",
    "# #     text=\"This is a test with zero-shot mode.\",\n",
    "# #     language=\"en\",\n",
    "# #     reference_audio=\"reference.wav\",\n",
    "# #     reference_text=\"Reference audio text\"\n",
    "# # )\n",
    "# # output_zs = cosyvoice.synthesize(request_zs)\n",
    "\n",
    "print(\"â­ï¸ CosyVoice3 í…ŒìŠ¤íŠ¸ëŠ” ì„ íƒì ì…ë‹ˆë‹¤. ì½”ë“œ ì£¼ì„ì„ ì œê±°í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”œ Part 7: GPT-SoVITS TTS í…ŒìŠ¤íŠ¸ (ì„ íƒì )\n",
    "\n",
    "âš ï¸ **ì£¼ì˜**: GPT-SoVITSëŠ” Git cloneì´ í•„ìš”í•˜ë©°, ì°¸ì¡° ì˜¤ë””ì˜¤ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-SoVITS í…ŒìŠ¤íŠ¸ (ì„ íƒì )\n",
    "# ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ ì œê±°\n",
    "\n",
    "# # GPT-SoVITS í´ë¡ \n",
    "# !git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
    "# \n",
    "# # PYTHONPATH ì„¤ì •\n",
    "# import sys\n",
    "# sys.path.insert(0, './GPT-SoVITS')\n",
    "# \n",
    "# # GPT-SoVITS ì—”ì§„ ë¡œë“œ\n",
    "# from vtts.engines.gptsovits import GPTSoVITSEngine\n",
    "# \n",
    "# gptsovits = GPTSoVITSEngine(model_id=\"kevinwang676/GPT-SoVITS-v3\")\n",
    "# gptsovits.load_model()\n",
    "# \n",
    "# # Voice cloning í…ŒìŠ¤íŠ¸ (ì°¸ì¡° ì˜¤ë””ì˜¤ í•„ìˆ˜)\n",
    "# # reference_audioëŠ” 5ì´ˆ ì´ìƒì˜ ê¹¨ë—í•œ ìŒì„±ì´ì–´ì•¼ í•¨\n",
    "# request = TTSRequest(\n",
    "#     text=\"ì•ˆë…•í•˜ì„¸ìš”, GPT-SoVITS ìŒì„± ë³µì œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "#     language=\"ko\",\n",
    "#     reference_audio=\"reference_voice.wav\",  # 5ì´ˆ+ ì°¸ì¡° ìŒì„±\n",
    "#     reference_text=\"ì°¸ì¡° ìŒì„±ì—ì„œ ë§í•œ í…ìŠ¤íŠ¸\"  # ì°¸ì¡° ì˜¤ë””ì˜¤ì˜ í…ìŠ¤íŠ¸\n",
    "# )\n",
    "# output = gptsovits.synthesize(request)\n",
    "\n",
    "print(\"â­ï¸ GPT-SoVITS í…ŒìŠ¤íŠ¸ëŠ” ì„ íƒì ì…ë‹ˆë‹¤. ì½”ë“œ ì£¼ì„ì„ ì œê±°í•˜ê³  ì°¸ì¡° ì˜¤ë””ì˜¤ë¥¼ ì¤€ë¹„í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
