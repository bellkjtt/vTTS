"""vTTS Command Line Interface"""

import click
import subprocess
import sys
from rich.console import Console
from rich.table import Table
from loguru import logger

from vtts.engines.registry import EngineRegistry
from vtts.server.app import create_app

console = Console()


@click.group()
@click.version_option()
def main():
    """vTTS - Universal TTS Serving System
    
    vLLM for Text-to-Speech
    """
    pass


@main.command()
@click.argument("model_id")
@click.option("--host", default="0.0.0.0", help="ì„œë²„ í˜¸ìŠ¤íŠ¸")
@click.option("--port", default=8000, help="ì„œë²„ í¬íŠ¸")
@click.option("--device", default="auto", help="ë””ë°”ì´ìŠ¤ (cuda, cpu, auto)")
@click.option("--workers", default=1, help="ì›Œì»¤ ìˆ˜")
@click.option("--cache-dir", default=None, help="ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬")
@click.option("--log-level", default="INFO", help="ë¡œê·¸ ë ˆë²¨")
@click.option("--stt-model", default=None, help="STT ëª¨ë¸ (Whisper, ì„ íƒì )")
def serve(model_id: str, host: str, port: int, device: str, workers: int, cache_dir: str, log_level: str, stt_model: str):
    """TTS ëª¨ë¸ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    
    Examples:
        vtts serve Supertone/supertonic-2
        vtts serve FunAudioLLM/Fun-CosyVoice3-0.5B-2512 --port 8000
        vtts serve kevinwang676/GPT-SoVITS-v3 --device cuda:0
    """
    # ë¡œê·¸ ì„¤ì •
    logger.remove()
    logger.add(sys.stderr, level=log_level)
    
    console.print(f"[bold green]ğŸš€ Starting vTTS Server[/bold green]")
    console.print(f"Model: [cyan]{model_id}[/cyan]")
    console.print(f"Host: [cyan]{host}:{port}[/cyan]")
    console.print(f"Device: [cyan]{device}[/cyan]")
    
    # ì—”ì§„ í™•ì¸
    engine_class = EngineRegistry.get_engine_for_model(model_id)
    if engine_class is None:
        console.print(f"[bold red]âŒ No engine found for model: {model_id}[/bold red]")
        console.print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì—”ì§„:")
        list_models()
        sys.exit(1)
    
    console.print(f"Engine: [cyan]{engine_class.__name__}[/cyan]")
    
    # STT ëª¨ë¸ í™•ì¸
    if stt_model:
        console.print(f"STT Model: [cyan]{stt_model}[/cyan]")
    
    # ì„œë²„ ì‹¤í–‰
    import uvicorn
    
    app = create_app(
        model_id=model_id,
        device=device,
        cache_dir=cache_dir,
        stt_model_id=stt_model
    )
    
    console.print("\n[bold green]âœ“ Server starting...[/bold green]")
    console.print(f"[dim]OpenAI compatible API: http://{host}:{port}/v1[/dim]")
    console.print(f"[dim]Docs: http://{host}:{port}/docs[/dim]\n")
    
    uvicorn.run(
        app,
        host=host,
        port=port,
        workers=workers,
        log_level=log_level.lower()
    )


@main.command()
def list_models():
    """ì§€ì›í•˜ëŠ” ëª¨ë¸ ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    console.print("\n[bold]ì§€ì›í•˜ëŠ” TTS ì—”ì§„ ë° ëª¨ë¸:[/bold]\n")
    
    supported = EngineRegistry.list_supported_models()
    
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("ì—”ì§„", style="cyan", width=15)
    table.add_column("ì§€ì› ëª¨ë¸ íŒ¨í„´", style="green")
    table.add_column("ì˜ˆì‹œ", style="yellow")
    
    examples = {
        "supertonic": "Supertone/supertonic-2",
        "cosyvoice": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
        "gptsovits": "kevinwang676/GPT-SoVITS-v3"
    }
    
    for engine_name, patterns in supported.items():
        table.add_row(
            engine_name,
            ", ".join(patterns),
            examples.get(engine_name, "-")
        )
    
    console.print(table)
    console.print()


@main.command()
@click.argument("model_id")
def info(model_id: str):
    """ëª¨ë¸ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    console.print(f"\n[bold]Model Information:[/bold] [cyan]{model_id}[/cyan]\n")
    
    engine_class = EngineRegistry.get_engine_for_model(model_id)
    
    if engine_class is None:
        console.print(f"[bold red]âŒ No engine found for model: {model_id}[/bold red]")
        sys.exit(1)
    
    # ì„ì‹œë¡œ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë¸ ë¡œë“œí•˜ì§€ ì•ŠìŒ)
    try:
        engine = engine_class(model_id=model_id)
        info_dict = engine.get_model_info()
        
        table = Table(show_header=False)
        table.add_column("ì†ì„±", style="cyan", width=25)
        table.add_column("ê°’", style="green")
        
        table.add_row("Engine", engine_class.__name__)
        table.add_row("Model ID", info_dict["model_id"])
        table.add_row("Device", info_dict["device"])
        table.add_row("Sample Rate", f"{info_dict['sample_rate']} Hz")
        table.add_row("Streaming Support", "âœ“" if info_dict["supports_streaming"] else "âœ—")
        table.add_row("Zero-shot Support", "âœ“" if info_dict["supports_zero_shot"] else "âœ—")
        table.add_row("Supported Languages", ", ".join(info_dict["supported_languages"]))
        
        console.print(table)
        console.print()
        
    except Exception as e:
        console.print(f"[bold red]Error:[/bold red] {e}")
        sys.exit(1)


@main.command()
@click.option("--fix", is_flag=True, help="ë¬¸ì œë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤")
@click.option("--cuda", is_flag=True, help="CUDA ì§€ì›ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤")
def doctor(fix: bool, cuda: bool):
    """í™˜ê²½ì„ ì§„ë‹¨í•˜ê³  ë¬¸ì œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
    
    Examples:
        vtts doctor          # í™˜ê²½ ì§„ë‹¨
        vtts doctor --fix    # ìë™ ìˆ˜ì •
        vtts doctor --cuda   # CUDA ì§€ì› ì„¤ì¹˜
    """
    import torch
    
    console.print("\n[bold]ğŸ©º vTTS Environment Diagnosis[/bold]\n")
    
    issues = []
    
    # ============================================================
    # 1. Python ë²„ì „ í™•ì¸
    # ============================================================
    py_version = sys.version_info
    py_str = f"{py_version.major}.{py_version.minor}.{py_version.micro}"
    
    if py_version >= (3, 10) and py_version < (3, 13):
        console.print(f"[green]âœ“[/green] Python: {py_str}")
    else:
        console.print(f"[red]âœ—[/red] Python: {py_str} (3.10-3.12 ê¶Œì¥)")
        issues.append("python")
    
    # ============================================================
    # 2. numpy ë²„ì „ í™•ì¸
    # ============================================================
    try:
        import numpy as np
        np_version = np.__version__
        
        # numpy 2.0 ì´ìƒì€ í˜¸í™˜ì„± ë¬¸ì œ ìˆìŒ
        major = int(np_version.split('.')[0])
        if major >= 2:
            console.print(f"[red]âœ—[/red] numpy: {np_version} (1.24-1.26 ê¶Œì¥, 2.x í˜¸í™˜ì„± ë¬¸ì œ)")
            issues.append("numpy")
        else:
            console.print(f"[green]âœ“[/green] numpy: {np_version}")
    except ImportError:
        console.print("[red]âœ—[/red] numpy: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        issues.append("numpy")
    
    # ============================================================
    # 3. ONNX Runtime í™•ì¸
    # ============================================================
    try:
        import onnxruntime as ort
        ort_version = ort.__version__
        providers = ort.get_available_providers()
        
        has_cuda = "CUDAExecutionProvider" in providers
        
        if has_cuda:
            console.print(f"[green]âœ“[/green] onnxruntime: {ort_version} (CUDA ì§€ì›)")
        else:
            console.print(f"[yellow]![/yellow] onnxruntime: {ort_version} (CPU ì „ìš©)")
            if cuda or torch.cuda.is_available():
                issues.append("onnxruntime-gpu")
        
        console.print(f"  [dim]Providers: {', '.join(providers)}[/dim]")
        
    except ImportError:
        console.print("[red]âœ—[/red] onnxruntime: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        issues.append("onnxruntime")
    
    # ============================================================
    # 4. PyTorch & CUDA í™•ì¸
    # ============================================================
    torch_version = torch.__version__
    cuda_available = torch.cuda.is_available()
    
    if cuda_available:
        cuda_version = torch.version.cuda
        gpu_name = torch.cuda.get_device_name(0)
        console.print(f"[green]âœ“[/green] PyTorch: {torch_version} (CUDA {cuda_version})")
        console.print(f"  [dim]GPU: {gpu_name}[/dim]")
    else:
        console.print(f"[yellow]![/yellow] PyTorch: {torch_version} (CPU ì „ìš©)")
    
    # ============================================================
    # 5. vTTS í™•ì¸
    # ============================================================
    try:
        import vtts
        console.print(f"[green]âœ“[/green] vTTS: ì„¤ì¹˜ë¨")
    except ImportError:
        console.print("[red]âœ—[/red] vTTS: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        issues.append("vtts")
    
    # ============================================================
    # ê²°ê³¼ ìš”ì•½
    # ============================================================
    console.print()
    
    if not issues:
        console.print("[bold green]âœ… ëª¨ë“  í™˜ê²½ì´ ì •ìƒì…ë‹ˆë‹¤![/bold green]\n")
        return
    
    console.print(f"[bold yellow]âš ï¸ {len(issues)}ê°œì˜ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:[/bold yellow]")
    for issue in issues:
        console.print(f"  - {issue}")
    
    if not fix:
        console.print("\n[dim]ìë™ ìˆ˜ì •: vtts doctor --fix[/dim]")
        console.print("[dim]CUDA ì„¤ì¹˜: vtts doctor --fix --cuda[/dim]\n")
        return
    
    # ============================================================
    # ìë™ ìˆ˜ì •
    # ============================================================
    console.print("\n[bold]ğŸ”§ ìë™ ìˆ˜ì • ì¤‘...[/bold]\n")
    
    # numpy ìˆ˜ì •
    if "numpy" in issues:
        console.print("[cyan]â†’[/cyan] numpy ì¬ì„¤ì¹˜ ì¤‘...")
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "numpy", "-y", "-q"], 
                      capture_output=True)
        subprocess.run([sys.executable, "-m", "pip", "install", "numpy>=1.24.0,<2.0.0", "-q"],
                      capture_output=True)
        console.print("[green]âœ“[/green] numpy ì„¤ì¹˜ ì™„ë£Œ")
    
    # onnxruntime ìˆ˜ì •
    if "onnxruntime" in issues or "onnxruntime-gpu" in issues:
        console.print("[cyan]â†’[/cyan] onnxruntime ì¬ì„¤ì¹˜ ì¤‘...")
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "onnxruntime", "onnxruntime-gpu", "-y", "-q"],
                      capture_output=True)
        
        if cuda or torch.cuda.is_available():
            subprocess.run([sys.executable, "-m", "pip", "install", "onnxruntime-gpu>=1.16.0", "-q"],
                          capture_output=True)
            console.print("[green]âœ“[/green] onnxruntime-gpu ì„¤ì¹˜ ì™„ë£Œ")
        else:
            subprocess.run([sys.executable, "-m", "pip", "install", "onnxruntime>=1.16.0", "-q"],
                          capture_output=True)
            console.print("[green]âœ“[/green] onnxruntime ì„¤ì¹˜ ì™„ë£Œ")
    
    console.print("\n[bold green]âœ… ìˆ˜ì • ì™„ë£Œ![/bold green]")
    console.print("[dim]ë³€ê²½ì‚¬í•­ ì ìš©ì„ ìœ„í•´ Pythonì„ ì¬ì‹œì‘í•˜ì„¸ìš”.[/dim]\n")


@main.command()
@click.option("--engine", default="supertonic", help="ì„¤ì¹˜í•  ì—”ì§„ (supertonic, gptsovits, cosyvoice, all)")
@click.option("--cuda/--no-cuda", default=True, help="CUDA ì§€ì› ì—¬ë¶€")
def setup(engine: str, cuda: bool):
    """ì—”ì§„ë³„ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.
    
    Examples:
        vtts setup --engine supertonic         # Supertonic (CPU)
        vtts setup --engine supertonic --cuda  # Supertonic (GPU)
        vtts setup --engine gptsovits          # GPT-SoVITS (ì €ì¥ì†Œ ìë™ í´ë¡ )
        vtts setup --engine all                # ëª¨ë“  ì—”ì§„
    """
    import torch
    import os
    from pathlib import Path
    
    console.print(f"\n[bold]ğŸ“¦ vTTS ì—”ì§„ ì„¤ì¹˜: {engine}[/bold]\n")
    
    # CUDA ìë™ ê°ì§€
    if cuda and not torch.cuda.is_available():
        console.print("[yellow]âš ï¸ CUDAê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.[/yellow]")
        cuda = False
    
    total_steps = 4 if engine in ["gptsovits", "all"] else 3
    step = 1
    
    # numpy ë¨¼ì € ì„¤ì¹˜ (í˜¸í™˜ì„±)
    console.print(f"[cyan]â†’[/cyan] [{step}/{total_steps}] numpy í˜¸í™˜ì„± í™•ì¸...")
    subprocess.run([sys.executable, "-m", "pip", "uninstall", "numpy", "-y", "-q"],
                  capture_output=True)
    subprocess.run([sys.executable, "-m", "pip", "install", "numpy>=1.24.0,<2.0.0", "-q"],
                  capture_output=True)
    step += 1
    
    # onnxruntime ì„¤ì¹˜
    console.print(f"[cyan]â†’[/cyan] [{step}/{total_steps}] onnxruntime ì„¤ì¹˜...")
    subprocess.run([sys.executable, "-m", "pip", "uninstall", "onnxruntime", "onnxruntime-gpu", "-y", "-q"],
                  capture_output=True)
    
    if engine in ["supertonic", "all"] and cuda:
        subprocess.run([sys.executable, "-m", "pip", "install", "onnxruntime-gpu>=1.16.0", "-q"],
                      capture_output=True)
    elif engine == "supertonic":
        subprocess.run([sys.executable, "-m", "pip", "install", "onnxruntime>=1.16.0", "-q"],
                      capture_output=True)
    step += 1
    
    # ============================================================
    # GPT-SoVITS: ì €ì¥ì†Œ ìë™ í´ë¡  ë° ì„¤ì¹˜
    # ============================================================
    if engine in ["gptsovits", "all"]:
        console.print(f"[cyan]â†’[/cyan] [{step}/{total_steps}] GPT-SoVITS ì €ì¥ì†Œ ì„¤ì¹˜...")
        
        # ì„¤ì¹˜ ê²½ë¡œ ê²°ì •
        gpt_sovits_path = os.environ.get("GPT_SOVITS_PATH")
        
        if not gpt_sovits_path:
            # ê¸°ë³¸ ê²½ë¡œ: ~/.vtts/GPT-SoVITS
            vtts_dir = Path.home() / ".vtts"
            vtts_dir.mkdir(exist_ok=True)
            gpt_sovits_path = vtts_dir / "GPT-SoVITS"
        else:
            gpt_sovits_path = Path(gpt_sovits_path)
        
        if gpt_sovits_path.exists():
            console.print(f"  [dim]GPT-SoVITS already exists: {gpt_sovits_path}[/dim]")
            console.print("  [dim]Pulling latest changes...[/dim]")
            result = subprocess.run(
                ["git", "-C", str(gpt_sovits_path), "pull"],
                capture_output=True, text=True
            )
        else:
            console.print(f"  [dim]Cloning to: {gpt_sovits_path}[/dim]")
            result = subprocess.run(
                ["git", "clone", "--depth", "1",
                 "https://github.com/RVC-Boss/GPT-SoVITS.git",
                 str(gpt_sovits_path)],
                capture_output=True, text=True
            )
            
            if result.returncode != 0:
                console.print(f"[red]âŒ Git clone failed: {result.stderr}[/red]")
                return
        
        # GPT-SoVITS requirements ì„¤ì¹˜
        console.print("  [dim]Installing GPT-SoVITS requirements...[/dim]")
        req_file = gpt_sovits_path / "requirements.txt"
        
        if req_file.exists():
            result = subprocess.run(
                [sys.executable, "-m", "pip", "install", "-r", str(req_file), "-q"],
                capture_output=True, text=True
            )
            if result.returncode != 0:
                console.print(f"[yellow]âš ï¸ Some requirements failed, but continuing...[/yellow]")
        
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì•ˆë‚´
        console.print(f"\n[green]âœ“[/green] GPT-SoVITS installed: {gpt_sovits_path}")
        
        # ìë™ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í˜„ì¬ ì„¸ì…˜)
        os.environ["GPT_SOVITS_PATH"] = str(gpt_sovits_path)
        
        console.print("\n[bold yellow]âš ï¸ í™˜ê²½ë³€ìˆ˜ë¥¼ ì˜êµ¬ ì„¤ì •í•˜ë ¤ë©´:[/bold yellow]")
        console.print(f"  [dim]export GPT_SOVITS_PATH={gpt_sovits_path}[/dim]")
        console.print(f"  [dim]ìœ„ ëª…ë ¹ì„ ~/.bashrc ë˜ëŠ” ~/.zshrcì— ì¶”ê°€í•˜ì„¸ìš”[/dim]")
        
        step += 1
    
    # ì—”ì§„ë³„ ì˜ì¡´ì„± ì„¤ì¹˜
    console.print(f"[cyan]â†’[/cyan] [{step}/{total_steps}] {engine} ì˜ì¡´ì„± ì„¤ì¹˜...")
    
    extras = {
        "supertonic": "supertonic-cuda" if cuda else "supertonic",
        "gptsovits": "gptsovits",
        "cosyvoice": "cosyvoice",
        "all": "all"
    }
    
    extra = extras.get(engine, "supertonic")
    
    # GitHubì—ì„œ ì„¤ì¹˜
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "-q",
         f"vtts[{extra}] @ git+https://github.com/bellkjtt/vTTS.git"],
        capture_output=True,
        text=True
    )
    
    if result.returncode == 0:
        console.print(f"\n[bold green]âœ… {engine} ì—”ì§„ ì„¤ì¹˜ ì™„ë£Œ![/bold green]")
        
        if engine == "gptsovits":
            console.print("\n[dim]ì‚¬ìš©ë²•: vtts serve kevinwang676/GPT-SoVITS-v3 --device cuda[/dim]")
            console.print("[dim]ì°¸ê³ : reference_audioì™€ reference_text íŒŒë¼ë¯¸í„°ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤![/dim]\n")
        else:
            console.print("\n[dim]ì‚¬ìš©ë²•: vtts serve Supertone/supertonic-2[/dim]\n")
    else:
        console.print(f"\n[bold red]âŒ ì„¤ì¹˜ ì‹¤íŒ¨[/bold red]")
        console.print(f"[dim]{result.stderr}[/dim]")


if __name__ == "__main__":
    main()
